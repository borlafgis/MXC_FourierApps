# 2. Foundations of the Fourier transform

```{python}
import numpy as np
import math
import matplotlib.pyplot as plt
import pylab as pl
# from IPython import display
import time as ttime
import random
from mpl_toolkits.mplot3d import Axes3D
```


To understand the Fourier transform from a mathematical and a computational
perspective, you need to understand sine waves, complex numbers and
the dot product. Integrating the first two leads to complex sine waves,
whereas the last two lead to the complex dot product, the two base concepts
to understand the complex Fourier coefficients and the Fourier transform.

# Complex numbers

The real number line is centered at 0, and stretches infinitely, containing all
numbers, both negative (left) and positive (right). On this line, each number
carries two pieces of information: its sign, and its magnitude, indicating
wether if its at the left or the right of 0, and how far it is. This mental
model is good for many cases, but there are problems in mathematics, physics,
engineering, or signal processing that are more tractable working with a number
plane defined with a real, and an imaginary axis ($x$ and $y$, respectively).

The basis of the real axis is the number one, and the basis for the imaginary
axis is the operator $i = \sqrt{-1}$. It is called the imaginary operator
because there is not a quantity that actually exists because no squared number
can be negative. $i$ was created with the intent to solve $x^{2} + 1 = 0$,
where $x = i$. Note the imaginary operator can be written as $i$ or $j$.
Mathematicians tend to prefer the former, whereas engineers use the latter
because $i$ is used for electrical current intensity. 

Also note many mathematicians, scientists and teachers have complained about
using the word 'imaginary'. Even Gauss, who formalized the system of complex
numbers and showed how to use complex numbers for calculus and geometry, hated
the term imaginary and instead suggested that we use the term lateral. But
for better or worse, imaginary is the standard term that everyone uses.

The important thing to keep in mind is the fact Fourier transform uses these
two-component complex numbers. Complex numbers have are referred to using the
real and imaginary axis coordinates, just like how you would refer to $x$
and $y$ coordinates on a normal Cartesian plane.

So at this point, here is 23I, which means two units over positive on the real
xis and three units positive on the imaginary axis.

The reason why complex numbers are so useful is that they pack a lot of
information into a very compact representation. So for just the real number
line, a number has only two pieces of information. Its distance away from the
origin and its sign meaning, whether it's to the left or to the right of zero.

A complex number not only contains the real and imaginary coordinates, also
define a line between this point ant the origin $(0, 0)$, which has an specific
length and an angle relative to the axis... by convention, the positive real
axis.

The Fourier transform returns complex numbers and the distance (magnitude)
and the angle represent the amplitude and the phase at some frequency.

The key to computing the distance from the origin is to think about magnitude
as the hypotenuse of a right triangle where the other two sides are the
projection of the real and imaginary parts into their respective axes.
thus, the squared distance is $|z|^{2}= real(z)^{2} + imag(z)^{2}$. The other
way to calculate the magnitude is to multiply the number by its complex
conjugate, which is the number with the sign of the imaginary part flipped.

$$
zz^{*} = (a + ib)(a - ib) = a^{2} + aib - aib - (bi)^{2} = a^{2} + b^{2}
$$

The other piece of information that we extract from a complex number is the
angle of this line relative to the positive real axis.

From trigonometry we know that the tangent of this angle theta is equal to
the ratio of the imaginary part to the real part. The angle itself can be
computed by calculating the inverse tangent, the arctangent of the fraction.

$$
\tan (\theta) = \frac{imag(z)}{real(z)}
\rightarrow
\theta = \arctan \frac{imag(z)}{real(z)} 
$$

Here, I'm showing that there are several ways to compute a complex number in
Python. One possibility is to add a real and imaginary number and the other
is to use the function `complex`, whose arguments are the real and imaginary
parts, respectively.

```{python}
# writing the complex number as real + imaginary
z = 4 + 1j*3
print(z)

# using the function complex
z = complex(4,3)    # this way
z = complex('4+3j') # or this way
print(z)
```

It is possible to extract the real and imaginary parts of a complex number
using the functions `np.real` and `np.imag`, respectively. Then, it is possible
to plot this number on the complex plane: four units positive on the real axis
and three units positive on the imaginary axis.

```{python}
# plot the complex number on the complex plane

plt.plot(np.real(z),np.imag(z),'ro')

# some plotting touch-ups
plt.axis('square')
plt.axis([-5, 5, -5, 5])
plt.grid(True)
plt.xlabel('Real axis'), plt.ylabel('Imaginary axis')
plt.show()
```

The magnitude of that number (distance away from the origin) can be calculated
using the Pythagorean theorem, or by using the absolute value (`np.abs`), which
is less verbose.

```{python}
# compute the magnitude of the complex number using Pythagorean theorem
mag = np.sqrt( np.real(z)**2 + np.imag(z)**2 )
mag = np.abs(z)

print( 'The magnitude is',mag )
```

If the two sides are three and four, then the hypotenuse must be five.

The angle between the positive real axis and the line connecting the origin
and the complex point can be calculated as the arctangent of the imaginary part
by the real part. It is also possible to use the simpler function `np.angle`

```{python}
phs = math.atan( np.imag(z) / np.real(z) )
phs = np.arctan2(np.imag(z), np.real(z))
phs = np.angle(z)

print( 'The angle is',phs )
```

![XKCD on complex numbers](https://imgs.xkcd.com/comics/complex_numbers.png)

# Euler's formula

Euler's formula is related to complex numbers and Fourier transform: it will
provide a compact notation for representing a lot of detailed spectral
information. It also directly leads to what many people consider to be the most
beautiful equation in all of mathematics.

$$
e^{ik} = \cos(k) + i \sin(k)
$$

$e$ is a famous constant in mathematics that appears in trigonometry, complex
analysis, differential equations or simulations. It is an irrational number
(it keeps going on and on and on forever with no known pattern or limit).
Its approximate value is $e = 2.718...$.

If we plot $e^{x}$ we can see the function always remains positive, starting
from near-zero values when $x$ is negative, and having increasingly larger
values when $x$ is positive.

The derivative of $e^{x}$ is the very same function, which is quite a special
property, although that's not really what we care about here.

Exponentiation of $e$ with a complex number gives $e^{ik}$, where $i$ is the
imaginary operator and $k$ is some number (sometimes written as $\phi$ or
$\theta$).

Euler's formula says that $e^{ik} = \cos(k) + i \sin(k)$. It is a neat formula
because it provides a link between complex numbers and trigonometry.
In particular, if you think about an axis with cosine and sine defining the
two axes, then all values of k, which is the angle of this line here, are
somewhere on this unit circle. You might remember one of the trig identities,
which says that cosine squared plus sine squared equals one, and that means
that for any value K here, this expression corresponds to a unit length vector,
a line that has a length of exactly one placed on the unit circle.

In other words, $e^{ik}$ describes a vector from the origin to some point on
a circle with radius one. Let's have a look in Matlab before moving forwards.

```{python}
# Euler's formula with arbitrary vector magnitude

magnitudes = [1, .5]
phases = [2/np.pi, np.pi/2]

# Make the plots
fig = plt.figure()
cart = plt.subplot(121)
polar = plt.subplot(122, projection='polar')

# Cartesian base
x = np.linspace(-np.pi,np.pi,num=100)
cart.plot(np.cos(x), np.sin(x), 'k', zorder=0)
cart.set_aspect('equal')
cart.grid(True)
cart.set_ylabel('Imaginary axis')
cart.set_xlabel('Real axis')

# Polar base
polar.set_yticks([.5])
polar.set_ylim(top=1)
polar.set_xticks(np.arange(np.pi/4, 2 * np.pi, np.pi/2))

#loop along values
for m, k in zip(magnitudes, phases):

    # The number
    c_number = m * np.exp( 1j * k )

    # Cartesian
    cart.plot([0, m * np.cos(k)], [0, m * np.sin(k)], zorder=1)
    cart.scatter(m * np.cos(k), m * np.sin(k), zorder=2)

    # Polar
    # extract magnitude and angle
    mag = np.abs(c_number)
    phs = np.angle(c_number)
    polar.plot([phs, phs], [0, mag])
    polar.scatter(phs, mag, zorder=2)
```

Here we are plotting a dot on the complex plane. The $x$ the cosine or the
real axis, and $y$ the sine or imaginary axis. Regardless on how arbitrarily 
large or small $k$ is, it still represents a point on this unit circle
on the plane.

So far we have talked about are unit vectors (magnitude of one), which lie on
this unit circle in the complex plane, meaning $k$ is specified on radians.

When $k = \pi$, then $e^{i\pi} = -1 + 0i$, which can be rewritten as
$e^{i\pi} + 1 = 0$. This expression is considered the most beautiful and
elegant mathematical equation ever discovered in human civilization.
It contains four of the most important numbers in mathematics (the rational
numbers $0$ and $1$, and the irrational numbers $e$ and $\pi$), as well as
the the three fundamental arithmetic operations (addition, multiplication
and exponentiation).

To use Euler's formula to describe a vector that is longer or shorter than
the unit circle, it is necessary to multiply this vector by some scalar
(single number, e.g., $m$ for magnitude). This scalar, only changes the
distance away from the origin. So this gives us

$$
m e^{ik} = m ( \cos(k) + i \sin(k) ) = m \cos(k) + m i \sin(k)
$$

$m$ is the magnitude or amplitude, and $k$ is the phase angle $(\theta)$.
This is why Euler's formula is so practical for Fourier analysis: it is
possible to read the critical information right off the number.

First we define a magnitude $m$ and an angle $k$, to generate a complex
number in Euler's notation. Then it is converted into rectangular notation
or Cartesian notation, where you see the projection onto the real axis,
the projection onto the imaginary axis, and we can extract the distance away
from the origin and the angle relative to the positive real axis.

Notice is the dissociation between the length and the angle of the vector.

# Sine waves and complex sine waves

Complex sine waves, are the result of embedding a regular sine wave into
Euler's formula. A formula for a simple sine wave is:

$$
a \sin ( 2 \pi f t + \theta)
$$

The sine wave has three parameters: amplitude $(a)$, frequency $(f)$, and
phase $(\theta)$. Frequency refers to the time between two points with the
same value (e.g., between peaks or troughs). It conveys the same information
as the terms 'periodicity', 'interval', or 'cycle'. Frequency usually is
conveyed as Hertz, the number of cycles per unit of time. For example, a sine
wave at one hertz repeats itself once every second. A five hertz sine wave
means five cycles per second or one cycle every 200 milliseconds.
And point one hertz means one cycle every 10 seconds. Here you see a few
examples of frequencies that you might be familiar with:

* Resting heart rate is around 60 beats per minute, which is around one beat
  per second (1 Hz).
* Breathing is around 15 breaths per minute, or one breath every four seconds.
  And that's around 2.5 Hertz.
* Brain electrical activity fluctuates at around 10 hertz (alpha band).
* FM radio is modulated sine waves in the megahertz range, and most movies
  play at 30 frames per second, which is 30 hertz.
* The cesium-133 isotope, which is used to synchronize clocks and satellites,
  oscillates at over nine trillion hertz, which is really, really fast.

Phase is quantified as the value of the sine wave as it crosses the point
corresponding to time equals zero. Ultimately phase angle reflects the shift
of the sine wave on the $x$ axis. Phase is a circular measure, it goes into
a cycle, not just from negative to positive or left to right (se unit on UNIT).
Two of the most important phases for sine waves are $0$ and $\pi/2$. These two
phases define what are commonly called a sine wave and a cosine wave. An
important property of sine and cosine is that they are orthogonal.

The third property of a sine wave is its amplitude, distance between the trough
and the peak, or the distance between zero and the peak, in case the signal is
centered around $0$.

Amplitude frequency and phase are independent of each other, meaning that none
of the features determines any of the other features.

Now I will show you some sine waves in Python. First we generate a vector of
time points ranging between from zero to two seconds with 500 samples per
second (sampling or discretization rate). Then we use the formula
$\sin (2 \pi f t + \theta)$ to generate the wave as such.

```{python}
# simulation parameters
srate = 500; # sampling rate in Hz
time  = np.arange(0.,2.,1./srate) # time in seconds

# sine wave param.eters
freq = 3;    # frequency in Hz
ampl = 2;    # amplitude in a.u.
phas = np.pi/3; # phase in radians

# generate the sine wave
sinewave = ampl * np.sin( 2*np.pi * freq * time + phas )

plt.plot(time,sinewave,'k')
plt.xlabel('Time (sec.)')
plt.ylabel('Amplitude (a.u.)')
plt.show()
```

Sine and cosine are the same function, but they are orthogonal: cosine has a
phase shift of $\pi/2, 90^{\circ}$, which is perpendicular to the real axis,
and straight upwards along the imaginary axis.

It is possible to think about amplitude and phase on the polar plane
because amplitude is a non-negative linear measure, and phase is a circular
measure.

```{python}
# sine and cosine are the same but for a phase shift

# generate the sine wave
sinewave = ampl * np.sin( 2*np.pi * freq * time + phas )
coswave  = ampl * np.cos( 2*np.pi * freq * time + phas )

plt.plot(time,sinewave,'k',label='sine')
plt.plot(time,coswave,'r',label='cosine')
plt.xlabel('Time (sec.)'), plt.ylabel('Amplitude')
plt.title('A sine and cosine with the same parameters.')
plt.show()
```

# Complex sine waves

An imaginary sine wave can be made in the same way an complex number is made:
by multiplying by the imaginary operator $i$. Therefore, a complex sine wave
also can be made by combining a real part with an imaginary part.

So what should be the real part and the imaginary part of a complex sine wave?
Well, it's really just about taking sine waves with any pair of phases.
However, $0$ and $\pi/2$ make a lot of sense because that corresponds to
the real and the imaginary axes, or cosine and sine. This brings us back to
to Euler's formula $e^{ik} = \cos(k) + i \sin(k)$, with
$k = 2 \pi f t + \theta$, and thus $e^{ik} = e^{i 2 ft [+\theta]}$ ($\theta$
is optional).


So this is a complex sine wave... a time series with a real and an imaginary
part (3D function). Now I'm going to switch to use Python as a tool to help
to the equation  and its meaning. The formula of a complex sine wave is 

$$
a e^{i 2 \pi f t + \theta}
$$

this is applied to the `time`vector, and we can just plot the real and the
imaginary parts on a 2D plot.

```{python}
# complex sine waves

# general simulation parameters
srate = 500; # sampling rate in Hz
time  = np.arange(0.,2.,1./srate) # time in seconds

# sine wave parameters
freq = 5;    # frequency in Hz
ampl = 2;    # amplitude in a.u.
phas = np.pi/3; # phase in radians

# generate the sine wave
csw = ampl * np.exp( 1j* (2*np.pi * freq * time + phas) );

# plot the results
plt.plot(time,np.real(csw),label='real')
plt.plot(time,np.imag(csw),label='imag')
plt.xlabel('Time (sec.)'), plt.ylabel('Amplitude')
plt.title('Complex sine wave projections')
plt.legend()
plt.show()
```

We also can show the complex sine wave in 3D, where the axis are time and the
real and imaginary parts. If we display the plane formed by time and the real
or the imaginary axis we get a cosine or a sine, respectively.

```{python}
# now show in 3D
fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.plot(time,np.real(csw),np.imag(csw))
ax.set_xlabel('Time (s)'), ax.set_ylabel('Real part'), ax.set_zlabel('Imag part')
ax.set_title('Complex sine wave in all its 3D glory')
plt.show()
```

## Why we need sine waves

We need sine waves because if we tried to compute the Fourier transform with
just real valued sines or cosines, the result would depend on the phase offset
between the sine wave and the signal: shifting changing the phase would alter
the spectrum even though the signal hasn't changed. Complex sine waves are just
the right solution when used alongside the complex dot product .


# VIDEO: The dot product

The dot product is a simple procedure that underlies many signal processing
techniques such as correlation, covariance, convolution, filtering and,
of course, the Fourier transform.

* I will explain both the algebraic and the geometric interpretations of the dot product.

The dot product is a single number that tells you about the relationship
between two vectors ('lists') of numbers with the same number of elements.
It can be expressed using algebra and using geometry. On the algebraic
interpretation two vectors with the same number of elements are lined up,
multiply each element in vector $a$ by the same element by in the vector $b$

$$
\begin{bmatrix}
    1 \\ 3 \\ 0 \\ 5
\end{bmatrix}
·
\begin{bmatrix}
    0 \\ 8 \\ 1 \\ 6
\end{bmatrix}
=
1 \times 0 + 3 \times 8 + 0 \times 1 + 5 \times 6
=
54
$$

There are several ways to implement the dot product in Python. A possibility
is to perform element-wise multiplication, and the sum the elements of the
resulting vector, or simply use the  the function `np.dot`.

```{python}
# two vectors
v1 = [ 1, 2, 3 ];
v2 = [ 3, 2, 1 ];

# compute the dot product
dp = sum( np.multiply(v1,v2) )

print('The dot product is',dp)
```

In the geometric interpretation the two vectors are interpreted as two lines
whose dot product is equivalent to the product of their lengths, times the
cosine of the angle between the two vectors.

$$
d = |v||w| \cos (\theta_{vw})
$$


* The algebraic and the geometric interpretation reflect the same concept
(law of cosines and some algebra... see the course).

The geometric interpetation provides two key insights about the dot product.

* When the two vectors are perpendicular the dot product between the two 
  vectors is $0$ because the cosine of $90^{\circ}$, or $\pi/2$, is $0$.
  In this specific case the length of the vectors would is irrelevant.
* The sign of the dot product reflects the relationship between the two
  If they meet at an acute angle $(\theta < 90^{\circ})$ the cosine is
  positive whereas it is negative if the angle is obtuse
  $(\theta > 90^{\circ})$, leading to a positive valued dot product.

The other terms $(|v|, |w|)$ are just lengths (always non-negative), and
they do not change the sign of the product.

$$
\begin{bmatrix}
    -3 \\ -1 \\ 1 \\ 3
\end{bmatrix}
·
\begin{bmatrix}
    -2 \\ -1 \\ 1 \\ 2
\end{bmatrix}
=
6 + 1 + 1 + 6
=
14
$$

If we multiply all the elements of the one vector by $-1$ the magnitude remains
the same, but the sign has flipped.

$$
\begin{bmatrix}
    -3 \\ -1 \\ -1 \\ -3
\end{bmatrix}
·
\begin{bmatrix}
    2 \\ 1 \\ -1 \\ -2
\end{bmatrix}
=
-6 - 1 - 1 - 6
=
-14
$$

Note this 'sign' property of the dot product only kolds if the vectors are
mean-centered, meaning the average of all the numbers within each vector is
zero.

When the dot product is positive, the two vectors go up and down together, 
and when the dot product is negative, when one vector goes up, the other
vector goes down.

## What is the dot product really?

What does it mean to have a single number that represents the relationship
between two vectors?

One way to think about this is to consider the correlation coefficient.
A correlation is a way of measuring the relationship between two variables.
The point is that the correlation coefficient is a single number that tells
us about the relationship between two variables, where the variables have the
same number of elements.

The magnitude of the correlation tells you about the strength of the
relationship, and the sign of the correlation coefficient tells you whether
the two variables are positively or negatively related to each other.

And why am I telling you about correlation now? Because it turns out that the
correlation coefficient is computed as the dot product between the
two variables.

$$
r = \frac{ \sum^{n}_{i=1}(x_i-\bar{x})(y_i-\bar{y}) }{%
        \sqrt{\sum^{n}_{i=1}(x_i-\bar{x})^2}\sqrt{\sum^{n}_{i=1}(y_i-\bar{y})^2}}
$$

Pearson correlation coefficient contains two normalization factors, one for
mean centering, and the denominator. The point is that the numerator has
element-wise multiplication between the two vectors whose elements are summed
up just afterwards, the very definition of the product.

When interpreting the dot product, you can think about as a 'correlation
coefficient' of sorts. In a Fourier transform, these normalizations are absent,
and thus the result is different, but MXC thinks there are similarities and
it's useful to see this link.

Now, we are going to use Python to compute the dot product between sine waves
of different frequencies, or different phases.

```{python}
# dot products of sine waves

# general simulation parameters
srate = 500; # sampling rate in Hz
time  = np.arange(0.,2.,1./srate) # time in seconds

# sine wave parameters
freq1 = 5;    # frequency in Hz
freq2 = 5;    # frequency in Hz

ampl1 = 2;    # amplitude in a.u.
ampl2 = 2;    # amplitude in a.u.

phas1 = np.pi/2; # phase in radians
phas2 = np.pi/2; # phase in radians

# generate the sine wave
sinewave1 = ampl1 * np.sin( 2*np.pi * freq1 * time + phas1 );
sinewave2 = ampl2 * np.sin( 2*np.pi * freq2 * time + phas2 );

# compute dot product
dp = np.dot(sinewave1,sinewave2);

# print result
print('dp =',dp)
```

* If both waves are identical the dot product is 2000.
* If the frequency of the sine waves are different, the dot product becomes $0$
  (well, a minuscule number close to $0$).
* When you use frequencies that are in steps of $1$ one $0.5$, the dot product 
  will haves non-zero values. The reason for this is because of the sampling
  rate, a the subtle but important features of the FT implemented and computers
  (important, but explained later).
* When the frequencies of the two sinewaves are the same, but the phases
  differ by $\pi/2$ the dot product becomes $0$. A phase offset of $\pi/2$,
  which corresponds to a sine and a cosine, means that the two signals, the
  two sine waves, are orthogonal to each other.

Now, I'd like to try computing the dot product between a signal and a set of
sinewaves with different frequencies. The signal is called a Morlet wavelet,
a sine wave tapered by a Gaussian ($\exp \left( -t^{2} \right) / \sigma$).

```{python}
# with a signal

# phase of signal
theta = 1*np.pi/4;


# simulation parameters
srate = 1000;
time  = np.arange(-1.,1.,1./srate)

# signal
sinew  = np.sin(2*np.pi*5*time + theta)
gauss  = np.exp( (-time**2) / .1);
signal = np.multiply(sinew,gauss)

# plot signal
plt.plot(time,signal)
plt.xlabel('Time (sec.)'), plt.ylabel('Amplitude (a.u.)')
plt.title('Signal')
plt.show()
```

`sinefrex` contains the frequencies to be used for the different sinewaves.
Within the loop we calculate a new real-valued sine wave, and calculate the
dot product between the wave and the wavelet. At the end we just make a stem
plot of the frequencies by the dot product.

```{python}
# Prepare the time frequencies
srate = 1000;
time  = np.arange(-1.,1.,1./srate)
sinefrex = np.arange(2.,10.,.5);

# Prepare the plot
fig, axarr = plt.subplots(2, 1)
for multi in [0, 1, 2]:

  # Set the theta and the line width
  theta = multi * np.pi/4
  width = (multi + 1)

  # generate the wavelet and plot
  morlet = np.sin(2 * np.pi * 5 * time + theta) * np.exp( (-time**2) / .1)
  axarr[0].plot(time, morlet)

  # initialize dot products vector
  dps_real = np.zeros(len(sinefrex))
  dps_cpx = np.zeros(len(sinefrex), dtype=complex)
  
  # Generate the wavelets and the dot products
  for fi in range(len(sinefrex)):

      # create real-valued sine wave and compute the dot product
      sinew = np.sin( 2 * np.pi * sinefrex[fi] * time)
      dps_real[fi] = np.dot(sinew, morlet)/len(time)

      # create sine wave
      bothw = np.exp( 1j * 2 * np.pi * sinefrex[fi] * time )
      dps_cpx[fi] = np.abs(np.vdot(bothw, morlet)/len(time))

  # and plot
  color =  axarr[0].lines[-1].get_color()
  axarr[1].vlines(sinefrex, 0, dps_real, colors=color, lw=3*width,
                  label='$' + str(multi) + r' \times \pi/4$')

  axarr[1].scatter(sinefrex, dps_cpx, color='k')
  axarr[1].set_ylim(0)

axarr[0].set_ylabel('Amplitude (a.u.)')
axarr[0].set_xlabel('Time (sec.)')
axarr[0].set_title('Morlet wavelet')

axarr[1].legend(title=r'Offset ($\theta$)')
axarr[1].set_title('Dot products with sine waves')
axarr[1].set_ylabel('Dot product (unsigned magnitude)')
axarr[1].set_xlabel('Sine wave frequency (Hz)')
fig.tight_layout()
```

The plot shows the dot product grows larger as we approach the frequency of
the signal (5 Hz), which you can see here.

Notice the wavelet remains the same, while sine waves are changing. That
means that these differences in the dot product magnitudes could be attributed
to the similarity between one another depending on the frequency of the wave.

If the phrase offset of the signal `theta` is not $0$ it becomes obvious
the resulting dot product spectrum is highly dependent on the phase of the
signal, even though these sine waves are not dependent on this theta phase.

with a theta = $1/4 \pi$ the wavelet shifts a little on the $x$ axis, and the
dot products have decreased a little. When I set the phase to be $\pi/2$,
all dot products become zero.

Now, this is a pretty awkward feature of this analysis, the way I've set this
up here, because the point of the Fourier transform is to determine how much
energy there is at a frequency in a signal, and the exact phase really
shouldn't matter. So clearly we need something else, and that something else
is going to be a complex dot product resulting from a complex sine wave.

## In this video

* Introduced you to the dot product
* algebraic and geometric interpretations
* dot product is related to the correlation coefficient
* the dot product of sine wave of different frequencies is 0
* the dot product of orthogonal sine waves $(\theta = \pi/2)$ is $0$.
* The dot product of a signal and a sine wave at different frequencies is 
  highly dependent on the phase relationship between the signal and those 
  sine waves.

# The complex dot product

The complex dot product is just an extension of the real-valued dot product
where one or both of the vectors contain complex numbers. The real part of
the complex dot product reflects the dot product with the real part between
the two signals, and the imaginary part of the complex dot product reflects
the dot product with the imaginary part of the signals: we are just computing
the dot product with two different signals in one computation.

This illustrates the practical usefulness of working with complex numbers:
We can implement two equations at the same time using one operation.

In the real-valued dot product, the magnitude of the dot product encodes the
strength of the relationship between the two vectors, just like the magnitude
of the correlation coefficient indicates the strength of the relationship
between the two variables.

It's exactly the same idea for the complex dot product, with the difference
that the magnitude of the complex dot product is the distance away from the
origin, regardless of the sign or the orientation of this vector. So it's not
just the real part or just the imaginary part; it's the combination of these
two, using the Pythagorean theorem to obtain the length of this line.

And this is just a quick reminder of how to compute the magnitude, or the
length, of a complex dot product, a complex number, using the Pythagorean
theorem.

Now, I would like to return to the Python example, except here we are using
complex sine waves instead of real-valued sine waves. When using a real-valued
sine wave adjusting the phase of the signal, altered the magnitude of the
product. In this case we are not showing the dot product, because that is a
complex number, what we are showing is its magnitude, the distance of the
complex dot product from the origin of the complex plane.

In the real-valued example when $\theta = \pi/2$ all the dot products where
$\approx 0$. Now that we are working with a complex-valued sine wave the dot
product magnitude doesn't change.

Complex sine wave contains two sine waves at the same time: the cosine
corresponding to the real part, and the sine, the imaginary part. 
The intersection of the cosine and the sine affects the position of the dot
product, but it doesn't affect its magnitude, its distance away from the origin.

```{python}
# in more detail...

# phase of signal
theta = 1*np.pi/4;

# signal
sinew  = np.sin(2*np.pi*5*time + theta)
gauss  = np.exp( (-time**2) / .1)
signal = np.multiply(sinew,gauss)

# create sine and cosine waves
sinew = np.sin( 2*np.pi*5*time )
cosnw = np.cos( 2*np.pi*5*time )

# compute dot products
dps = np.dot( sinew,signal ) / len(time)
dpc = np.dot( cosnw,signal ) / len(time)

# combine sine and cosine into complex dot product
dp_complex = complex(dpc,dps) # cos/sin were swapped in the video
mag = np.abs(dp_complex)
phs = np.angle(dp_complex)

# and plot
plt.plot( dpc , dps ,'ro')
plt.xlabel('Cosine axis')
plt.ylabel('Sine axis')
plt.axis('square')
plt.grid(True)
plt.axis([-.2,.2,-.2,.2])
plt.show()

# draw a line using polar notation
plt.polar([phs,phs],[0,mag])
plt.show()
```

You can see that more clearly in this cell of code. It contains the same signal
we used in previous examples. What we are doing is creating a real-valued sine
wave and a real valued cosine wave, compute the dot product between the wavelet
and both imaginary and real-valued waves, sine and cosine,  which will be the
real and the imaginary part of a complex number. Setting the phase $(\theta)$
to any value does not allter the magnitude in any way regardless of the phase,
the angle relative to the positive real axis.

```{python}

# create complex sine wave
csw = np.exp( 1j*2*np.pi*5*time )
rsw = np.sin(    2*np.pi*5*time )

# specify range of phase offsets for signal
phases = np.arange(0, 2 * np.pi, np.pi/4) # np.linspace(0, 7 * np.pi/2, num=8)

# Prepare the colors
cmap = plt.get_cmap('hsv')
colors = cmap(np.linspace(0, 1, len(phases) + 1))

# create a figure as a subplot mosaic
fig = plt.figure(figsize=(5, 5), layout='constrained')
axes = fig.subplot_mosaic([['time', 'time'], ['complex', 'normal']])
axes['time'].set_title('Signal and sine wave over time')

# Plot rsw a single time
axes['time'].plot(time, rsw, color='k', lw=2.5, zorder=0)
axes['time'].set_xlim(-.75, .75)

for plot_id in ('complex', 'normal'):
    axes[plot_id].set_title(f"{plot_id.capitalize()} dot product")
    axes[plot_id].set_aspect('equal')
    axes[plot_id].set_ylim(-.175, .175)
    axes[plot_id].set_ylabel('Imaginary')
    axes[plot_id].set_xlim(-.175, .175)
    axes[plot_id].set_xlabel('Real')
    axes[plot_id].axhline(0, color='k', zorder=0)
    axes[plot_id].axvline(0, color='k', zorder=0)

for phi in range(0,len(phases)):

    # create signal
    sinew  = np.sin(2*np.pi*5*time + phases[phi])
    gauss  = np.exp( (-time**2) / .1)
    signal = np.multiply(sinew, gauss)

    # compute complex dot product
    cdp = np.sum( np.multiply(signal,csw) ) / len(time)

    # compute real-valued dot product
    rdp = sum( np.multiply(signal,rsw) ) / len(time)

    # plot signal and real part of sine wave
    axes['time'].plot(time, signal, color=colors[phi])

    # plot complex dot product
    axes['complex'].scatter(np.real(cdp), np.imag(cdp), color=colors[phi])
    axes['complex'].plot([0, np.real(cdp)], [0, np.imag(cdp)], color=colors[phi])

    # plot normal dot producr
    axes['normal'].scatter(rdp, 0, color=colors[phi])
```

On the last illustration we are just shifting the signal phase over time
$(0 - 7\pi/2)$, and computing the complex dot product with a complex sine
wave, and a real valued sine wave.

The same signal is a sine wave at five hertz, multiplied, or tapered by, a
Gaussian. The only thing that's changing is the phase offset of this signal.
Then we just calculate the dot product between the signal and both complex
and real-valued sine waves, and plot.

The real valued dot product is fluctuates back and forth on the real axis.
There are some specific phases where the real valued dot product is exactly
zero. In contrast, the complex dot product is just floating around on a circle:
the magnitude does not changing for different relative phases between the
signal and the sine wave.

## Summary

Complex are used as a convenient tool to adress the fact the dot product
between a sine wave and a signal is phase dependent.

The main thing to keep in mind is that the cosine and the sine correspond to
the real and the imaginary parts of a complex sine wave.

And that using a complex sine wave allows us to implement computations in a
efficient way.
