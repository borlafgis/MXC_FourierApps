# The fast Fourier transform

```{python}
import numpy as np
import math
import matplotlib.pyplot as plt
import random
import timeit
import scipy.fftpack
from mpl_toolkits.mplot3d import Axes3D
```

## How the FFT works, speed tests

The loop-based implementation of the discrete time Fourier transform, only is
useful as simple example to demistify its inner mechanisms, but is too slow
for practical applications. The actual fast Fourier transform (FFT) first
places all of the [template?] complex sine waves as the columns of a matrix
(one column per wave), and the signal in a column vector, and then apply matrix multiplication (instead of applying the dot product in a loop). The next step
is to decompose this matrix into a lot of separate matrices that are very
sparse (mostly zeroes), which can be easily processed by modern computers.
A more detailed description would require to delve deeper into concepts from
linear algebra, such as matrix decomposition. The point here is that is
advisable to use the highly efficient implementations of that are readily
available.

### Python

To test the speed of our slow implementation, and the faster one provided by
Scipy, we create the a fully random signal with `np.random.randn`and apply
both implementations. The only novelty is the tic-toc variables, that
store when `timeit.default_timer()` has been called. By substracting the
timestamps we see how long the function has taken.

```{python}
# create the signal
pnts   = 1000
signal = np.random.randn(pnts)


# start the timer for "slow" Fourier transform
tic = timeit.default_timer()

# prepare the Fourier transform
fourTime = np.array(range(0,pnts))/pnts
fCoefs   = np.zeros(len(signal),dtype=complex)

for fi in range(pnts):
    csw = np.exp( -1j*2*np.pi*fi*fourTime )
    fCoefs[fi] = np.sum( np.multiply(signal,csw) )


# end timer for slow Fourier transform
toc = timeit.default_timer()
t1 = toc-tic

# time the fast Fourier transform
tic = timeit.default_timer()
fCoefsF = scipy.fftpack.fft(signal)
toc = timeit.default_timer()
t2 = toc-tic

# and plot
plt.bar([1,2],[t1,t2])
plt.title('Computation times')
plt.ylabel('Time (sec.)')
plt.xticks([1,2], ['loop','FFT'])
plt.show()

```

The loop-based transform is much slower!. This difference grows with the length
of the signal, so it is wise to use the faster version.

### We still need to apply normalization!

Note that the FFT still needs: two aforementioned normalizations so the 
amplitude is correct: dividing the Fourier coefficients by the number of points
in the signal (`npnts`), and multiply the positive frequencies by $2$ to
account for the negative frecuencies (but not the 0th frecuency, the DC
component!).

```{python}
## fft still need normalizations

srate = 1000
time  = np.arange(0,2,1/srate)
npnts = len(time)

# signal
signal = 2*np.sin(2*np.pi*6*time)

# Fourier spectrum
signalX = scipy.fftpack.fft(signal)
hz = np.linspace(0,srate,npnts)

# amplitude
ampl = np.abs(signalX[0:len(hz)])

plt.stem(hz,ampl)
plt.xlim(0,10)
plt.xlabel('Frequency (Hz)')
plt.ylabel('Amplitude (a.u.)')
plt.show()
```

# Inverse fast Fourier transform

The inverse fast fourier transform is called IFFT. It is applied directly to
the Fourier coefficients, and just reconstructs the signal. Of course, it 
does not really make sense to just transform back and forth, but it is very
useful to apply some signal processing techniques, for example, applying
filters on the frecuency domain, and reconstruct inn the time domain.

```{python}
# set parameters
srate = 1000
time  = np.arange(0,3,1/srate)
pnts  = len(time)

# create multispectral signal
signal  = np.multiply( (1+np.sin(2*np.pi*12*time)) , np.cos(np.sin(2*np.pi*25*time)+time) )

# fft
signalX = scipy.fftpack.fft(signal)

# reconstruction via ifft
reconSig = scipy.fftpack.ifft(signalX)

plt.plot(time,signal,label='Original')
plt.plot(time,np.real(reconSig),label='Reconstructed')
plt.xlabel('Time (sec.)')
plt.ylabel('amplitude (a.u.)')
plt.show()
```

# The perfection of the Fourier transform

No information is lost when using the Fourier transform to go from the time
domain to the frequency domain. This can be explained from the perspective of statistics and linear multiple regression, and the other comes from linear
algebra.

## Statistics explanation.

The idea of a multiple regression is to explain variance in a dependent variable
(outcome), using some independent variables (predictors).

A statistical model has a characteristic called the degrees of freedom (DoF),
which decreases with the number of predictors (more predictors, smaller DoF).
When the DoF is zero, it the model will explain the signal with no errors
(100% of the variance explaining, "memorizing" the data, a proces called
overfitting).

In the case of the Fourier transform, the input time series would be the
dependent variable, and each template sine wave would be a predictor. We have
the same number of predictors as data points in the dependent variable, which
means that it is a statistical model has zero degrees of freedom. In statistics
this would mean the model is overfit and cannot be generalize, but in this
context it means that our transform has fully captured all the variability
appearing in the data.

## Algebra explanation

For the linear algebra explanation, we start by creating the matrix $F$ where
the template complex sine waves are the columns. If we have $n$, there will be
$n$ sine waves, so it will be a square matrix with size $n \times n$. Each sine
wave is independent from the rest, which means this is a full rank matrix, and
these are always invertible. This has two implications:

1. There's always a unique solution to this equation $s \times F = c$, where
$s$ is the vector of the signal, $F$ is this Fourier matrix, and $C$ is the
vector of Fourier coefficients. It does not matter what $s$ is, it's always
going to be in our $n$, and $F$ fully covers (spans) all that space. That means
$s$ can always be represented using any set of basis vectors (the Fourier
matrix, uses complex sine waves as basis vectors).

2. Because $F$ is invertible, we can reconstruct $s$ perfectly by putting the
inverse of the Fourier transform on the right side of both of these equations
($s = c F^{-1}$). This aso explains why there is a sign flip of the imaginary
part of the complex sine waves in the negative frequencies: $F$ times its
inverse must be equal to the identity matrix ($F \times F^{-1} = I$), so
therefore the imaginary parts of $F$ must cancel with the imaginary parts of
its inverse.

## Python

Here, I'm creating the $F$ matrix with a loop, creating the template a complex
sines waves for each frequency with a length equal to the number of points of a
hypotetical signal (`pnts`).  Then we calculate $F^{-1}$, its explicit inverse
of matrix $F$.

```{python}
# number of time points
pnts = 1000 

# prepare the Fourier transform
fourTime = np.array(range(0,pnts))/pnts
F        = np.zeros((pnts,pnts),dtype=complex)

for fi in range(0,pnts):
    # create complex sine wave
    csw = np.exp( -1j*2*np.pi*fi*fourTime )
    
    # put csw into column of matrix F
    F[:,fi] = csw

# compute inverse of F (and normalize by N)
Finv = np.linalg.inv(F)*pnts
```
Now we plot the real and the imaginary parts of a column ($5^{th}$) of matrix
$F$ and the same column of its inverse. The first row is the forward Fourier
transform matrix, and the second is its inverse. The real parts of these
signals, are represented in blue, and they are the same. The orange lines
represent the imaginary parts. These share the same frequency, but their
sign is flipped: one gets up when the other goes down, and down when the other
goes up. Thus, when you add these two, the imaginary parts will cancel,
retaining just the real part.

```{python}
col = 5
direct_c, inv_c = F[:, col], Finv[:, col]

fig, panels = plt.subplots(2, 1, sharex=True)

panels[0].plot(fourTime, np.real(direct_c), label=r"$\Re(F)$", c="lightgray")
panels[0].plot(fourTime, np.real(inv_c), label=r"$\Re(F^{-1})$", c="k", ls=":")
panels[0].legend(loc="upper right")

panels[1].plot(fourTime, np.imag(direct_c), label=r"$\Im(F)$", c="lightgray")
panels[1].plot(fourTime, np.real(inv_c), label=r"$\Im(F^{-1})$", c="k", ls=":")
panels[1].legend(loc="upper right")
fig.tight_layout()
```

By the way, this Fourier matrix looks really neat if you make an image of that.

```{python}
plt.imshow(np.real(F))
```

# Using the fft on matrices


```{python}
# using the matlib library
import numpy.matlib

# generate multivariate dataset

srate = 400
time  = np.arange(0,srate*2)/srate
npnts = len(time)
nreps = 50

# dataset is repeated sine waves
data = np.matlib.repmat( np.sin(2*np.pi*10*time), nreps,1 )
```


```{python}
# FFT of data along each dimension

dataX1 = scipy.fftpack.fft(data,axis=0) / npnts
dataX2 = scipy.fftpack.fft(data,axis=1) / npnts
hz = np.linspace(0,srate/2,int(np.floor(npnts/2)+1))

# check sizes
print(np.shape(dataX1))
print(np.shape(dataX2))
```


```{python}
# show data and spectra!
plt.imshow(data)
plt.xlabel('Time')
plt.ylabel('Channel')
plt.title('Time-domain signal')
plt.show()

plt.stem(hz,np.mean( 2*abs(dataX1[:,:len(hz)]),axis=0),'k')
plt.xlabel('Frequency (??)')
plt.ylabel('Amplitude')
plt.title('FFT over channels')
plt.show()

plt.stem(hz,np.mean( 2*abs(dataX2[:,:len(hz)]),axis=0),'k')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Amplitude')
plt.title('FFT over time')
plt.show()
```
